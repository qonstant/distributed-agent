stages:
  - build
  - deploy

.default-docker-job: &default-docker-job
  tags:
    - vps1
  before_script:
    - echo "Running on $(hostname)"
    - docker --version

build-docker-image:
  <<: *default-docker-job
  stage: build
  script:
    - cd python/rag_api
    # Build via compose to ensure local build and reproducible image
    - docker compose build --pull --no-cache

deploy-in-to-docker:
  <<: *default-docker-job
  stage: deploy
  script:
    - cd python/rag_api

    # --- safe debug of OPENAI_API_KEY (doesn't print key) ---
    - |
      echo "OPENAI_API_KEY set? ${OPENAI_API_KEY:+yes}"
      echo -n "$OPENAI_API_KEY" | wc -c | xargs printf "OPENAI_API_KEY length: %s\n"
      echo -n "$OPENAI_API_KEY" | sha256sum | awk '{print "OPENAI_API_KEY sha256:", $1}'

    # --- write .env file for docker-compose (job-local only) ---
    - |
      cat > .env <<EOF
      OPENAI_API_KEY=${OPENAI_API_KEY}
      S3_ENDPOINT=${S3_ENDPOINT}
      S3_BUCKET_VECTORS=${S3_BUCKET_VECTORS}
      S3_ACCESS_KEY_ID=${S3_ACCESS_KEY_ID}
      S3_SECRET_ACCESS_KEY=${S3_SECRET_ACCESS_KEY}
      EOF
      # ensure .env file is present and not world-readable (optional)
      chmod 600 .env

    # If you want a fresh /app/out cache from S3, set FORCE_S3_REFRESH=1 in CI variables
    - |
      if [ "${FORCE_S3_REFRESH}" = "1" ]; then
        echo "FORCE_S3_REFRESH enabled: tearing down and removing volumes"
        docker compose down -v --remove-orphans || true
      else
        docker compose down --remove-orphans || true
      fi

    # start/replace container (compose builds if necessary)
    - docker compose up -d --build

    # cleanup .env from runner workspace (optional but tidy)
    - shred -u .env || rm -f .env || true
