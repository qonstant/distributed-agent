stages:
  - build
  - deploy

# small before_script anchors
.before-vps1: &before-vps1
  - echo "Running on $(hostname)"
  - docker --version || true
  - docker-compose --version || true

.before-vps2: &before-vps2
  - echo "Running on $(hostname) (golang runner)"
  - docker --version || true
  - docker-compose --version || true

variables:
  IMAGE_NAME: "rag:latest"
  CONTAINER_NAME: "rag-container"
  BOT_IMAGE_NAME: "study-bot:latest"
  BOT_CONTAINER_NAME: "study-bot"
  GOLANG_IMAGE_NAME: "golang-agent:latest"
  GOLANG_CONTAINER_NAME: "golang-agent"

################################################################################
# RAG (python/rag_api)
################################################################################
build-rag-image:
  stage: build
  tags:
    - vps1
  before_script: *before-vps1
  script:
    - cd python/rag_api
    - docker build --no-cache -t "${IMAGE_NAME}" .

deploy-rag:
  stage: deploy
  tags:
    - vps1
  before_script: *before-vps1
  # ensure pipeline-level ordering: wait for deploy-bot job to finish first
  needs:
    - job: deploy-bot
      optional: true      # allow deploy-rag to run if deploy-bot is skipped
  script:
    - cd python/rag_api
    - 'echo "OPENAI_API_KEY set? ${OPENAI_API_KEY:+yes}"'
    - 'echo "OPENAI_API_KEY length: ${#OPENAI_API_KEY}"'
    - 'printf "OPENAI_API_KEY=%s\n" "${OPENAI_API_KEY}" > .env'
    - 'printf "S3_ENDPOINT=%s\n" "${S3_ENDPOINT}" >> .env'
    - 'printf "S3_BUCKET_VECTORS=%s\n" "${S3_BUCKET_VECTORS}" >> .env'
    - 'printf "S3_ACCESS_KEY_ID=%s\n" "${S3_ACCESS_KEY_ID}" >> .env'
    - 'printf "S3_SECRET_ACCESS_KEY=%s\n" "${S3_SECRET_ACCESS_KEY}" >> .env'
    - chmod 600 .env
    #
    # Wait-for-bot runtime guard: if bot docker files exist in repo root,
    # wait up to ~60s (adjust attempts/max to taste) for the bot container to be running.
    #
    - |
      if [ -f ../Dockerfile ] && [ -f ../docker-compose.yml ]; then
        echo "Bot artifacts found in repo root — waiting for ${BOT_CONTAINER_NAME} to be running..."
        attempts=0
        max=30
        sleep_seconds=2
        while [ $attempts -lt $max ]; do
          if docker ps --filter "name=${BOT_CONTAINER_NAME}" --filter "status=running" -q >/dev/null 2>&1; then
            echo "Detected ${BOT_CONTAINER_NAME} running."
            break
          fi
          echo "Waiting for ${BOT_CONTAINER_NAME} to start... ($attempts/$max)"
          attempts=$((attempts+1))
          sleep $sleep_seconds
        done
        if [ $attempts -ge $max ]; then
          echo "Timeout waiting for ${BOT_CONTAINER_NAME} — continuing with RAG deploy."
        fi
      else
        echo "No bot Dockerfile/docker-compose at repo root — not waiting."
      fi
    - 'if [ "${FORCE_S3_REFRESH}" = "1" ]; then docker-compose down -v --remove-orphans || true; else docker-compose down --remove-orphans || true; fi'
    - docker-compose up -d --build
    - 'shred -u .env || rm -f .env || true'

################################################################################
# BOT (study-bot) — runs only if Dockerfile + docker-compose.yml exist at repo root
################################################################################
build-bot-image:
  stage: build
  tags:
    - vps1
  before_script: *before-vps1
  rules:
    - exists:
        - Dockerfile
        - docker-compose.yml
  script:
    - cd .
    - docker build --no-cache -t "${BOT_IMAGE_NAME}" .

deploy-bot:
  stage: deploy
  tags:
    - vps1
  before_script: *before-vps1
  rules:
    - exists:
        - Dockerfile
        - docker-compose.yml
  script:
    - cd .
    - 'echo "OPENAI_API_KEY set? ${OPENAI_API_KEY:+yes}"'
    - 'echo "OPENAI_API_KEY length: ${#OPENAI_API_KEY}"'
    - 'printf "OPENAI_API_KEY=%s\n" "${OPENAI_API_KEY}" > .env'
    - 'printf "S3_ENDPOINT=%s\n" "${S3_ENDPOINT}" >> .env'
    - 'printf "S3_BUCKET=%s\n" "${S3_BUCKET}" >> .env'
    - 'printf "S3_ACCESS_KEY_ID=%s\n" "${S3_ACCESS_KEY_ID}" >> .env'
    - 'printf "S3_SECRET_ACCESS_KEY=%s\n" "${S3_SECRET_ACCESS_KEY}" >> .env'
    - chmod 600 .env
    - 'if [ "${FORCE_S3_REFRESH}" = "1" ]; then docker-compose down -v --remove-orphans || true; else docker-compose down --remove-orphans || true; fi'
    - docker-compose up -d --build
    - 'shred -u .env || rm -f .env || true'

################################################################################
# GOLANG service (uses runner 'vps2')
################################################################################
build-golang-image:
  stage: build
  tags:
    - vps2
  before_script: *before-vps2
  script:
    - cd golang
    - docker build --no-cache -t "${GOLANG_IMAGE_NAME}" .

deploy-golang:
  stage: deploy
  tags:
    - vps2
  before_script: *before-vps2
  script:
    - cd golang
    - 'printf "S3_ENDPOINT=%s\n" "${S3_ENDPOINT}" > .env'
    - 'printf "S3_BUCKET=%s\n" "${S3_BUCKET}" >> .env'
    - 'printf "S3_ACCESS_KEY_ID=%s\n" "${S3_ACCESS_KEY_ID}" >> .env'
    - 'printf "S3_SECRET_ACCESS_KEY=%s\n" "${S3_SECRET_ACCESS_KEY}" >> .env'
    - 'printf "OPENAI_API_KEY=%s\n" "${OPENAI_API_KEY}" >> .env'
    - chmod 600 .env
    - 'if [ "${FORCE_S3_REFRESH}" = "1" ]; then docker-compose down -v --remove-orphans || true; else docker-compose down --remove-orphans || true; fi'
    - docker-compose up -d --build
    - 'shred -u .env || rm -f .env || true'
